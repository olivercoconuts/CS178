{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mltools as ml\n",
    "from sklearn import *\n",
    "\n",
    "'''Try for order of importance of features'''\n",
    "# Error_single_feature = dict()\n",
    "# for i in range(14): \n",
    "#     random_forest = ensemble.RandomForestClassifier(\n",
    "#         n_estimators=500, min_samples_leaf= 4, oob_score = True, n_jobs=-1)\n",
    "#     random_forest.fit(Xtr[:,i:i+1], Ytr)    \n",
    "#     Error_single_feature[i] = 1-random_forest.score(Xva[:,i:i+1],Yva)\n",
    "    \n",
    "# print(sorted(Error_single_feature.keys(), key=lambda x: Error_single_feature[x]))\n",
    "\n",
    "# feature_most_important = [0, 13, 1, 6, 5, 9, 12, 10, 8, 2, 3, 7, 4, 11]\n",
    "\n",
    "'''Try for best combinations of top features'''\n",
    "# error_top_features = []\n",
    "# for i in range(14):\n",
    "#     Xtr_selected = np.ndarray(shape=(Xtr.shape[0],i+1))\n",
    "#     for feature_idx in range(i+1):\n",
    "#         feature = feature_most_important[feature_idx]\n",
    "#         Xtr_single_feature = Xtr[:,feature]\n",
    "#         Xtr_selected[:,feature_idx] = Xtr_single_feature\n",
    "#     random_forest = ensemble.RandomForestClassifier(\n",
    "#         n_estimators=500, min_samples_leaf= 4, oob_score = True, n_jobs=-1)\n",
    "#     random_forest.fit(Xtr_selected, Ytr)    \n",
    "#     Xva_selected = np.ndarray(shape=(Xva.shape[0],i+1))\n",
    "#     for feature_idx in range(i+1):\n",
    "#         feature = feature_most_important[feature_idx]\n",
    "#         Xva_single_feature = Xva[:,feature]\n",
    "#         Xva_selected[:,feature_idx] = Xva_single_feature\n",
    "#     error_top_features.append(1-random_forest.score(Xva_selected, Yva))\n",
    "# print(error_top_features)\n",
    "# Feature combinations get [0.31479999999999997, 0.31440000000000001, 0.30879999999999996,\n",
    "#                          0.31200000000000006, 0.30159999999999998, 0.30079999999999996, \n",
    "#                          0.3004, 0.30000000000000004, 0.30359999999999998, \n",
    "#                          0.29720000000000002, 0.29759999999999998, 0.29679999999999995, \n",
    "#                          0.29079999999999995, 0.29079999999999995]\n",
    "'''Decide to use all features'''\n",
    "\n",
    "class random_forest:\n",
    "    def predict(self, Xtr, Ytr, Xte):\n",
    "        rf = ensemble.RandomForestClassifier(\n",
    "                        n_estimators=500, min_samples_leaf= 4, n_jobs=-1 ,max_depth=13)\n",
    "        rf.fit(Xtr,Ytr)\n",
    "        return rf.predict(Xte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
