{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcoliver/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mcoliver/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/mcoliver/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import mltools as ml\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from sklearn import *\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"data/X_train.txt\",delimiter=None)\n",
    "Y = np.genfromtxt(\"data/Y_train.txt\",delimiter=None)\n",
    "Xte = np.genfromtxt('data/X_test.txt',delimiter=None)\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X[:10000], Y[:10000], 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 13 and input n_features is 14 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-abbb3c6e2e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mXva_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXva_single_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_sample_leaf:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\",error rate is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXva\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYva\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 13 and input n_features is 14 "
     ]
    }
   ],
   "source": [
    "# Build the classifiers\n",
    "\n",
    "'''Try for order of importance of features'''\n",
    "# Error_single_feature = dict()\n",
    "# for i in range(14): \n",
    "#     random_forest = ensemble.RandomForestClassifier(\n",
    "#         n_estimators=500, min_samples_leaf= 4, oob_score = True, n_jobs=-1)\n",
    "#     random_forest.fit(Xtr[:,i:i+1], Ytr)    \n",
    "#     Error_single_feature[i] = 1-random_forest.score(Xva[:,i:i+1],Yva)\n",
    "    \n",
    "# print(sorted(Error_single_feature.keys(), key=lambda x: Error_single_feature[x]))\n",
    "\n",
    "feature_most_important = [0, 13, 1, 6, 5, 9, 12, 10, 8, 2, 3, 7, 4, 11]\n",
    "\n",
    "'''Try for best combinations of top features'''\n",
    "# error_top_features = []\n",
    "# for i in range(14):\n",
    "#     Xtr_selected = np.ndarray(shape=(Xtr.shape[0],i+1))\n",
    "#     for feature_idx in range(i+1):\n",
    "#         feature = feature_most_important[feature_idx]\n",
    "#         Xtr_single_feature = Xtr[:,feature]\n",
    "#         Xtr_selected[:,feature_idx] = Xtr_single_feature\n",
    "#     random_forest = ensemble.RandomForestClassifier(\n",
    "#         n_estimators=500, min_samples_leaf= 4, oob_score = True, n_jobs=-1)\n",
    "#     random_forest.fit(Xtr_selected, Ytr)    \n",
    "#     Xva_selected = np.ndarray(shape=(Xva.shape[0],i+1))\n",
    "#     for feature_idx in range(i+1):\n",
    "#         feature = feature_most_important[feature_idx]\n",
    "#         Xva_single_feature = Xva[:,feature]\n",
    "#         Xva_selected[:,feature_idx] = Xva_single_feature\n",
    "#     error_top_features.append(1-random_forest.score(Xva_selected, Yva))\n",
    "# print(error_top_features)\n",
    "# Feature combinations get [0.31479999999999997, 0.31440000000000001, 0.30879999999999996,\n",
    "#                          0.31200000000000006, 0.30159999999999998, 0.30079999999999996, \n",
    "#                          0.3004, 0.30000000000000004, 0.30359999999999998, \n",
    "#                          0.29720000000000002, 0.29759999999999998, 0.29679999999999995, \n",
    "#                          0.29079999999999995, 0.29079999999999995]\n",
    "'''Decide to use all features'''\n",
    "# \n",
    "\n",
    "for i in range(1,14):\n",
    "    random_forest = ensemble.RandomForestClassifier(\n",
    "        n_estimators=500, min_samples_leaf= 4, oob_score = True, n_jobs=-1, max_features=i,max_depth=4)\n",
    "    Xtr_selected = np.ndarray(shape=(Xtr.shape[0],13))\n",
    "    for feature_idx in range(13):\n",
    "        feature = feature_most_important[feature_idx]\n",
    "        Xtr_single_feature = Xtr[:,feature]\n",
    "        Xtr_selected[:,feature_idx] = Xtr_single_feature\n",
    "    Xva_selected = np.ndarray(shape=(Xva.shape[0],13))\n",
    "    for feature_idx in range(13):\n",
    "        feature = feature_most_important[feature_idx]\n",
    "        Xva_single_feature = Xva[:,feature]\n",
    "        Xva_selected[:,feature_idx] = Xva_single_feature\n",
    "    random_forest.fit(Xtr_selected, Ytr)    \n",
    "    print(\"min_sample_leaf:\", i,\",error rate is\",1-random_forest.score(Xva,Yva))\n",
    "\n",
    "\n",
    "\n",
    "# prediction = random_forest.predict(Xva)\n",
    "# np.savetxt(\"Y_submit.txt\",\n",
    "#            np.vstack( (np.arange(len(prediction)) , prediction) ).T,\n",
    "#            '%d, %.2f',header='ID,Prob1',comments='',delimiter=',');\n",
    "\n",
    "# classifier_list = [(random_forest, 10)\n",
    "#                   ]\n",
    "# Yhat = []\n",
    "# for classifier in classifier_list:\n",
    "#     for weight in range(classifier[1]):\n",
    "#         Yhat.append(classifier[0].predict(Xva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# Yhat = predictSoft(Xtr)\n",
    "# mse(Yhat, Ytr)\n",
    "# auc(Yhat, Ytr)\n",
    "\n",
    "# end = time.time()\n",
    "\n",
    "# print('Seconds elapsed: %.4f' % (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
